# German Adaptation Configuration with Elastic Weight Consolidation (EWC)
# Supports German adaptation phase with catastrophic forgetting prevention

model:
  dutch_checkpoint: "models/pretrained/wav2vec2-dutch-pretrained"
  freeze_feature_encoder: true
  dropout: 0.1
  attention_dropout: 0.1
  activation_dropout: 0.0
  feat_proj_dropout: 0.1
  layerdrop: 0.05

data:
  train_metadata: "data/metadata/german/train.tsv"
  val_metadata: "data/metadata/german/val.tsv"
  sampling_rate: 16000
  max_duration_seconds: 20
  num_workers: 4

training:
  learning_rate: 1e-5  # Lower than Dutch pre-training
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  num_train_epochs: 3  # Fewer epochs for adaptation
  warmup_steps: 300
  max_steps: -1
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 2
  fp16: true
  fp16_opt_level: "O1"
  max_grad_norm: 1.0
  

ewc:
  enabled: true
  lambda: 0.4  # Regularization strength for catastrophic forgetting prevention
  fisher_samples: 1000
  compute_fisher: true

checkpointing:
  output_dir: "models/pretrained/wav2vec2-german-adapted"
  save_strategy: "steps"
  save_steps: 1000
  save_total_limit: 3
  load_best_model_at_end: true

logging:
  logging_strategy: "steps"
  logging_steps: 100
  report_to: ["tensorboard"]
  logging_dir: "results/logs/tensorboard/german_adaptation"

evaluation:
  evaluation_strategy: "steps"
  eval_steps: 500  # Evaluation frequency for adaptation
  metric_for_best_model: "loss"
  greater_is_better: false

early_stopping:
  enabled: true
  patience: 3

environment:
  seed: 42
  dataloader_num_workers: 4
  group_by_length: true
  length_column_name: "input_length"

runpod:
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 1
  fp16: true
  dataloader_num_workers: 8
  eval_steps: 250
