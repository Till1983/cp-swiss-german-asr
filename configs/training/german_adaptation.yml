# German Adaptation Configuration with Elastic Weight Consolidation (EWC)
# Supports German adaptation phase with catastrophic forgetting prevention
#
# NOTE: All paths are RELATIVE and will be resolved based on ENVIRONMENT:
#   - local: Uses /app/* base paths
#   - runpod: Uses /workspace/* base paths
# This ensures the config works across environments without modification.

model:
  # CHANGED: Relative path - script will prepend MODELS_DIR based on environment
  dutch_checkpoint: "pretrained/wav2vec2-dutch-pretrained"
  freeze_feature_encoder: true
  dropout: 0.1
  attention_dropout: 0.1
  activation_dropout: 0.0
  feat_proj_dropout: 0.1
  layerdrop: 0.05

data:
  # These paths are defined but currently UNUSED by script
  # Script uses hardcoded GERMAN_CV_ROOT instead
  # Keeping for future use if script is refactored
  train_metadata: "metadata/german/train.tsv"  # Relative to DATA_DIR
  val_metadata: "metadata/german/val.tsv"      # Relative to DATA_DIR
  sampling_rate: 16000
  max_duration_seconds: 20
  num_workers: 4

training:
  learning_rate: 1e-5  # Lower than Dutch pre-training
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  num_train_epochs: 3  # Fewer epochs for adaptation
  warmup_steps: 300
  max_steps: -1
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 2
  fp16: true
  fp16_opt_level: "O1"
  max_grad_norm: 1.0
  

ewc:
  enabled: true
  lambda: 0.4  # Regularization strength for catastrophic forgetting prevention
  fisher_samples: 5000  # Number of Dutch samples for Fisher estimation (5k = ~5% of data, follows EWC best practices)
  compute_fisher: true

checkpointing:
  # NOTE: Script overrides this with MODELS_DIR / "adapted" / "wav2vec2-german-adapted"
  # Keeping for documentation and potential future use
  output_dir: "adapted/wav2vec2-german-adapted"  # Relative to MODELS_DIR
  save_strategy: "steps"
  save_steps: 1000
  save_total_limit: 3
  load_best_model_at_end: true

logging:
  logging_strategy: "steps"
  logging_steps: 100
  report_to: ["tensorboard"]
  # NOTE: Script overrides this with OUTPUT_DIR / "logs"
  logging_dir: "logs/tensorboard/german_adaptation"  # Relative to RESULTS_DIR

evaluation:
  evaluation_strategy: "steps"
  eval_steps: 500  # Evaluation frequency for adaptation
  metric_for_best_model: "loss"
  greater_is_better: false

early_stopping:
  enabled: true
  patience: 3

environment:
  seed: 42
  dataloader_num_workers: 4
  group_by_length: true
  length_column_name: "input_length"

runpod:
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 1
  fp16: true
  dataloader_num_workers: 8
  eval_steps: 250